{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tuning a Keras Model with `kerastuner`",
   "id": "9b9059708847d922"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:23:07.662075Z",
     "start_time": "2025-03-14T20:23:07.657492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "#dataset = keras.datasets.mnist\n",
    "#dataset = keras.datasets.fashion_mnist\n",
    "\n",
    "# Boston housing: 404 data points: (x,y) = (x1 ... x13, y) where x1 thru x13 are parameters like\n",
    "# locale, crime rate, prop tax, and y = pricing.\n",
    "dataset = keras.datasets.boston_housing\n",
    "(x_train, y_train), (x_val, y_val) = dataset.load_data()\n",
    "\n",
    "print(f\"Dataset => {dataset}\"\n",
    "      f\"\\nshapes (x,y, x test, ytest) => {x_train.shape}, {y_train.shape}, {x_val.shape}, {y_val.shape}\"\n",
    "      f\"\\ndata types => {x_train.dtype}, {y_train.dtype}, {x_val.dtype}, {y_val.dtype}\")"
   ],
   "id": "15b3a27d13fe9150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset => <module 'keras.api.datasets.boston_housing' from '/Users/jcoles/Source/jkc/jims-ml-sandbox/.venv/lib/python3.10/site-packages/keras/api/datasets/boston_housing/__init__.py'>\n",
      "shapes (x,y, x test, ytest) => (404, 13), (404,), (102, 13), (102,)\n",
      "data types => float64, float64, float64, float64\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:04.039309Z",
     "start_time": "2025-03-14T20:49:04.034636Z"
    }
   },
   "source": [
    "from keras.src.layers import Dense\n",
    "from keras import layers, Model, optimizers\n",
    "from keras import Sequential\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "# class MyHyperModel(HyperModel):\n",
    "#     def build(self, hp):\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "#                         activation=hp.Choice('activation', ['relu', 'tanh'])))\n",
    "#         model.add(Dense(10, activation='softmax'))\n",
    "#         model.compile(optimizer=hp.Choice('optimizer', ['adam', 'sgd']),\n",
    "#                       loss='sparse_categorical_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "#         return model\n",
    "\n",
    "\n",
    "def build_mlp1_model(hp):\n",
    "    #    inputs = layers.Input(shape=(784,))\n",
    "    inputs = layers.Input(shape=(13,))\n",
    "    x = layers.Dense(units=hp.Int('units', min_value=16, max_value=64, step=16),\n",
    "                     activation=hp.Choice('activation', ['relu', 'sigmoid']))(inputs)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['mse']\n",
    "                  )\n",
    "    return model\n"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:07.761928Z",
     "start_time": "2025-03-14T20:49:07.746013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_mlp1_model,\n",
    "    objective='val_mse',  # Specify the metric to optimize\n",
    "    max_trials=10,  # Number of models to try\n",
    "    executions_per_trial=2,  # Average over 2 runs for each hyperparameter set\n",
    "    directory='my_dir',  # Directory to save search results\n",
    "    project_name='boston_tuning_example',  # Project name for organization\n",
    "    overwrite=True\n",
    ")\n"
   ],
   "id": "323d4ecdfc532bb1",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
   "id": "7902d0f46cf8c560",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 03s]\n",
      "val_mse: 341.1876525878906\n",
      "\n",
      "Best val_mse So Far: 63.784671783447266\n",
      "Total elapsed time: 00h 00m 25s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:49:51.634228Z",
     "start_time": "2025-03-14T20:49:49.253376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Optimal number of units in Dense layer: {best_hps.get('units')}\")\n",
    "print(f\"Optimal activation function: {best_hps.get('activation')}\")\n",
    "print(f\"Optimal optimizer: {best_hps.get('optimizer')}\")\n",
    "\n",
    "# Build the best model and re-train if necessary\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n"
   ],
   "id": "8ccad03da3363a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of units in Dense layer: 32\n",
      "Optimal activation function: relu\n",
      "Optimal optimizer: rmsprop\n",
      "Epoch 1/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 12502.6504 - mse: 12502.6504 - val_loss: 3834.6177 - val_mse: 3834.6177\n",
      "Epoch 2/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3215.4004 - mse: 3215.4004 - val_loss: 1024.4263 - val_mse: 1024.4263\n",
      "Epoch 3/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 876.7130 - mse: 876.7130 - val_loss: 384.0189 - val_mse: 384.0189\n",
      "Epoch 4/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 379.5747 - mse: 379.5747 - val_loss: 290.1783 - val_mse: 290.1783\n",
      "Epoch 5/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 317.7613 - mse: 317.7613 - val_loss: 245.2735 - val_mse: 245.2735\n",
      "Epoch 6/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 255.5800 - mse: 255.5800 - val_loss: 216.3833 - val_mse: 216.3833\n",
      "Epoch 7/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 204.6380 - mse: 204.6380 - val_loss: 181.1153 - val_mse: 181.1153\n",
      "Epoch 8/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 163.2070 - mse: 163.2070 - val_loss: 166.4660 - val_mse: 166.4660\n",
      "Epoch 9/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 168.0156 - mse: 168.0156 - val_loss: 141.4171 - val_mse: 141.4171\n",
      "Epoch 10/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 129.7504 - mse: 129.7504 - val_loss: 191.4263 - val_mse: 191.4263\n",
      "Epoch 11/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 155.9286 - mse: 155.9286 - val_loss: 158.0050 - val_mse: 158.0050\n",
      "Epoch 12/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 133.0222 - mse: 133.0222 - val_loss: 113.9692 - val_mse: 113.9692\n",
      "Epoch 13/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 111.1664 - mse: 111.1664 - val_loss: 167.3980 - val_mse: 167.3980\n",
      "Epoch 14/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 111.4294 - mse: 111.4294 - val_loss: 116.7728 - val_mse: 116.7728\n",
      "Epoch 15/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 94.0960 - mse: 94.0960 - val_loss: 160.0854 - val_mse: 160.0854\n",
      "Epoch 16/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 111.2918 - mse: 111.2918 - val_loss: 109.2521 - val_mse: 109.2521\n",
      "Epoch 17/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 71.4506 - mse: 71.4506 - val_loss: 170.7586 - val_mse: 170.7586\n",
      "Epoch 18/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 112.7378 - mse: 112.7378 - val_loss: 107.9461 - val_mse: 107.9461\n",
      "Epoch 19/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 92.3534 - mse: 92.3534 - val_loss: 170.0095 - val_mse: 170.0095\n",
      "Epoch 20/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 121.8072 - mse: 121.8072 - val_loss: 145.3085 - val_mse: 145.3085\n",
      "Epoch 21/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 103.6937 - mse: 103.6937 - val_loss: 81.0489 - val_mse: 81.0489\n",
      "Epoch 22/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 60.0350 - mse: 60.0350 - val_loss: 77.7003 - val_mse: 77.7003\n",
      "Epoch 23/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 56.4756 - mse: 56.4756 - val_loss: 88.2164 - val_mse: 88.2164\n",
      "Epoch 24/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 68.0989 - mse: 68.0989 - val_loss: 78.7853 - val_mse: 78.7853\n",
      "Epoch 25/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 79.3698 - mse: 79.3698 - val_loss: 164.7318 - val_mse: 164.7318\n",
      "Epoch 26/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 89.6425 - mse: 89.6425 - val_loss: 69.7290 - val_mse: 69.7290\n",
      "Epoch 27/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 55.6075 - mse: 55.6075 - val_loss: 70.6051 - val_mse: 70.6051\n",
      "Epoch 28/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 64.2808 - mse: 64.2808 - val_loss: 64.6452 - val_mse: 64.6452\n",
      "Epoch 29/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 60.2726 - mse: 60.2726 - val_loss: 64.8390 - val_mse: 64.8390\n",
      "Epoch 30/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 58.7011 - mse: 58.7011 - val_loss: 63.2948 - val_mse: 63.2948\n",
      "Epoch 31/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 63.4254 - mse: 63.4254 - val_loss: 81.2792 - val_mse: 81.2792\n",
      "Epoch 32/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 60.0044 - mse: 60.0044 - val_loss: 170.9138 - val_mse: 170.9138\n",
      "Epoch 33/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 99.2874 - mse: 99.2874 - val_loss: 59.2384 - val_mse: 59.2384\n",
      "Epoch 34/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 63.4512 - mse: 63.4512 - val_loss: 56.4413 - val_mse: 56.4413\n",
      "Epoch 35/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 53.7305 - mse: 53.7305 - val_loss: 62.5002 - val_mse: 62.5002\n",
      "Epoch 36/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 46.8397 - mse: 46.8397 - val_loss: 56.7561 - val_mse: 56.7561\n",
      "Epoch 37/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 47.5839 - mse: 47.5839 - val_loss: 83.3666 - val_mse: 83.3666\n",
      "Epoch 38/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 47.5552 - mse: 47.5552 - val_loss: 53.2054 - val_mse: 53.2054\n",
      "Epoch 39/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 51.3456 - mse: 51.3456 - val_loss: 51.7691 - val_mse: 51.7691\n",
      "Epoch 40/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 55.4688 - mse: 55.4688 - val_loss: 55.5428 - val_mse: 55.5428\n",
      "Epoch 41/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 47.6219 - mse: 47.6219 - val_loss: 67.8157 - val_mse: 67.8157\n",
      "Epoch 42/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 41.7253 - mse: 41.7253 - val_loss: 67.9543 - val_mse: 67.9543\n",
      "Epoch 43/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 54.5995 - mse: 54.5995 - val_loss: 72.6575 - val_mse: 72.6575\n",
      "Epoch 44/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 56.2992 - mse: 56.2992 - val_loss: 49.1551 - val_mse: 49.1551\n",
      "Epoch 45/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 42.8749 - mse: 42.8749 - val_loss: 94.9604 - val_mse: 94.9604\n",
      "Epoch 46/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 82.9277 - mse: 82.9277 - val_loss: 47.8861 - val_mse: 47.8861\n",
      "Epoch 47/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 39.9453 - mse: 39.9453 - val_loss: 65.7790 - val_mse: 65.7790\n",
      "Epoch 48/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 38.8943 - mse: 38.8943 - val_loss: 66.9365 - val_mse: 66.9365\n",
      "Epoch 49/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 44.1506 - mse: 44.1506 - val_loss: 164.8640 - val_mse: 164.8640\n",
      "Epoch 50/50\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 82.7850 - mse: 82.7850 - val_loss: 46.9388 - val_mse: 46.9388\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T20:50:02.027279Z",
     "start_time": "2025-03-14T20:50:02.024957Z"
    }
   },
   "cell_type": "code",
   "source": "tuner.results_summary()\n",
   "id": "d0b4092e7784654e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/boston_tuning_example\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_mse\", direction=\"min\")\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 63.784671783447266\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 70.82283782958984\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 48\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 82.92798233032227\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "Score: 84.91437911987305\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "Score: 107.76593780517578\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 121.0833625793457\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "activation: sigmoid\n",
      "optimizer: adam\n",
      "Score: 337.6020812988281\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "Score: 341.1876525878906\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "activation: sigmoid\n",
      "optimizer: adam\n",
      "Score: 468.1713409423828\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "activation: sigmoid\n",
      "optimizer: rmsprop\n",
      "Score: 490.2416534423828\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
