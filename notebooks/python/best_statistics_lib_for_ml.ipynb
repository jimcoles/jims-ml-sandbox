{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Best Statistics Libraries for Machine Learning\n",
    "\n",
    "In this notebook, we'll explore some of the best Python libraries for statistics and their specific use cases in machine learning. We'll provide examples for each library."
   ],
   "id": "92dbf2b417c7873a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SciPy\n",
    "\n",
    "SciPy is a robust library for scientific computing, which includes modules for optimization, integration, interpolation, eigenvalue problems, algebra, and statistics. It is widely used for advanced statistical methods and computations.\n",
    "\n",
    "One of the key features of SciPy is its `scipy.stats` module, which provides various statistical tests and probability distributions.\n",
    "\n",
    "### Example: Performing a t-test using `scipy.stats`"
   ],
   "id": "bfc0ea2db48b36f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from scipy import stats as sps\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "stat, p = sps.ttest_ind([1, 2, 3], [4, 5, 6])\n",
    "print(f\"t-statistic: {stat}, p-value: {p}\")\n",
    "\n",
    "# Calculate the Spearman rank-order correlation coefficient\n",
    "corr_spearman, p_spearman = sps.spearmanr([1, 2, 3], [3, 2, 1])\n",
    "print(f\"Spearman correlation coefficient: {corr_spearman}, p-value: {p_spearman}\")\n",
    "\n",
    "# Perform a chi-square test of independence\n",
    "data_contingency = [[10, 20], [15, 25]]\n",
    "chi2, p_chi2, dof, expected = sps.chi2_contingency(data_contingency)\n",
    "print(f\"Chi-square statistic: {chi2}, p-value: {p_chi2}, degrees of freedom: {dof}\")\n",
    "print(f\"Expected frequencies: \\n{expected}\")\n",
    "\n",
    "# Generate random samples from a normal distribution\n",
    "random_samples = sps.norm.rvs(loc=0, scale=1, size=10)\n",
    "print(f\"Random samples from a normal distribution: {random_samples}\")\n",
    "\n"
   ],
   "id": "ebebeaa8c5d59006"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Statsmodels\n",
    "\n",
    "Statsmodels is a Python library designed for statistical modeling and analysis. It offers tools for conducting various statistical tests, data exploration, and creating models such as regression, ANOVA, and time-series analysis.\n",
    "\n",
    "A particularly useful feature is its support for linear regression models coupled with comprehensive summaries of results.\n",
    "\n",
    "### Example: Linear regression using Statsmodels"
   ],
   "id": "49d059e42851bcd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Linear regression\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [5, 9, 11, 15, 18]\n",
    "X = sm.add_constant(X)  # Add constant for intercept\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ],
   "id": "fabc50ca2211cf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scikit-learn\n",
    "\n",
    "Scikit-learn is a powerful library for machine learning, but it also provides robust tools for data preprocessing and feature engineering. It includes functions for statistics-based preprocessing such as feature scaling, normalization, and encoding.\n",
    "\n",
    "### Example: Feature scaling using `StandardScaler`"
   ],
   "id": "4f6fda56a05cf4cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(scaled_data)"
   ],
   "id": "cec4c11189ad72a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a highly popular library for data manipulation and exploration. It is particularly well-suited for exploratory data analysis (EDA) and provides tools for descriptive statistics, grouping, merging, and reshaping datasets.\n",
    "\n",
    "### Example: Descriptive statistics using Pandas"
   ],
   "id": "f1a19bd2a9222f8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "print(data.describe())"
   ],
   "id": "292b18ead7c8a887"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PyMC and Bayesian Statistics\n",
    "\n",
    "PyMC is a library for Bayesian inference, allowing for probabilistic programming and building complex statistical models. It's commonly used in scenarios requiring problem-specific uncertainty modeling.\n",
    "\n",
    "### Example: Bayesian inference using PyMC3"
   ],
   "id": "573fe3ae74d6475d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pymc3 as pm   # pymc3 latest install requires an older version of numpy than is allowed by tensorflow\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=1)\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=1, observed=[-1, 0, 1])\n",
    "    trace = pm.sample(1000)"
   ],
   "id": "19c354dd3454b8f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recommendation Summary\n",
    "\n",
    "| Library       | Use Case                                                                                  |\n",
    "|---------------|-------------------------------------------------------------------------------------------|\n",
    "| **SciPy**     | Advanced statistical tests and probability distributions                                 |\n",
    "| **Statsmodels** | Statistical modeling, regression, and hypothesis testing                                |\n",
    "| **Scikit-learn** | Data preprocessing and features for machine learning workflows                         |\n",
    "| **Pandas**    | Exploratory data analysis (EDA) and basic descriptive statistics                          |\n",
    "| **PyMC**      | Bayesian inference and probabilistic programming                                          |\n",
    "\n",
    "### Practical Recommendations:\n",
    "- Use **SciPy** for stand-alone statistical tests.\n",
    "- Use **Statsmodels** for in-depth modeling and examining relationships in data.\n",
    "- Use **Scikit-learn** when working within a machine learning pipeline.\n",
    "- Use **Pandas** for exploration and quick statistical insights.\n",
    "- Use **PyMC** for advanced Bayesian analysis or probabilistic problem-solving."
   ],
   "id": "b973205e8f727afd"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
