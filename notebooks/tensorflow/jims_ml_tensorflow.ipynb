{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# A basic `TensorFlow` installation check\n",
    "\n",
    "Pre-reqs: If nothing is working right, check this notebook, [../jims_ml_notebook_env.py].\n",
    "\n",
    "A sanity check call to `tensorflow` to make sure it finds and loads the library. NOTE: this does not do any tensor processing:"
   ],
   "id": "2a9bc4e2ec05f5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"A TF computation: {tf.add(1, 5).numpy()}\")\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(f\"A TensorFlow string constant: {hello.numpy()}\")"
   ],
   "id": "3814a818a6d07176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Of special `import` for `keras`\n",
    "Keras notions should be imported from `keras.*`, not from `tensorflow`.\n",
    "\n",
    "When coding to the conventional API:"
   ],
   "id": "1315965ff70582e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Imports when using the conventional class-centric Keras API\n",
    "\n",
    "# from keras.api.datasets import mnist\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Input, Dense\n",
    "\n"
   ],
   "id": "d05cb1fe7133365a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "When coding to the newer functional Keras API:\n"
   ],
   "id": "c604df980cf7df0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import keras  # has keras.Model keras.Input etc\n",
   "id": "7fad8da6c28f3ff6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we load a dataset from the convenient tensorflow_datasets python package.",
   "id": "3d85093ca3d9c35d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import jkcsoft.ml.tfds_utils\n",
    "\n",
    "importlib.reload(jkcsoft.ml.tfds_utils)\n",
    "\n",
    "from jkcsoft.ml.tfds_utils import dump_dataset_info, display_dataset_info\n",
    "\n",
    "\n",
    "# Validates datasets package install and lists voluminous available datasets\n",
    "dump_dataset_info()\n",
    "\n",
    "# Create an array of 5 most popular datasets\n",
    "most_popular_datasets = ['mnist', 'cifar10', 'imdb_reviews', 'fashion_mnist', 'coco']\n",
    "print(f\"Most popular datasets: {most_popular_datasets}\")\n",
    "\n",
    "for dataset_name in most_popular_datasets:\n",
    "    display_dataset_info(dataset_name)\n"
   ],
   "id": "33d3dd51918dda5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup training and test datums to be used in the next two examples\n",
    "\n",
    "The common datums are used to compare the use of the two Keras APIs.\n"
   ],
   "id": "7174123b6113b98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from jkcsoft.ml.sandbox.tf_tinker import ModelTest, RunBatch\n",
    "\n",
    "# define a batch include a common dataset for all tests\n",
    "run_batch = RunBatch()\n",
    "run_batch.x_train = tf.constant([[1.0], [2.0], [3.0], [4.0]])\n",
    "run_batch.y_train = tf.constant([[2.0], [4.0], [6.0], [8.0]])\n",
    "run_batch.x_test = tf.constant([[5.0], [6.0]])\n",
    "run_batch.y_test = tf.constant([[10.0], [12.0]])"
   ],
   "id": "df1acb5bb736369",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A simple _conventional_ Keras pipeline with hard-coded TensorFlow datasets",
   "id": "9c6e7b2dc9d3b8ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a model using the conventional Keras class API\n",
    "model = Sequential([\n",
    "    Input(shape=(1,)),  # Input layer for single-dimensional input\n",
    "    Dense(32, activation=\"relu\"),  # kera.src.core.dense.Dense\n",
    "    Dense(16, activation=\"sigmoid\"),\n",
    "    Dense(16, activation=\"softmax\"),\n",
    "    Dense(1, activation=\"linear\")\n",
    "])\n",
    "\n",
    "test_common_dense = ModelTest().set_description(\"Common Dense Sequence\").set_model(model)\n",
    "test_common_dense.set_fit_epochs(10)\n",
    "\n",
    "# invoke model compile here\n",
    "test_common_dense.compile_model(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_absolute_percentage_error\",\n",
    "        \"mean_squared_error\",\n",
    "        \"root_mean_squared_error\",\n",
    "        \"accuracy\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"auc\",\n",
    "        \"binary_accuracy\"\n",
    "    ])\n",
    "\n",
    "# test_common_dense.model.fit()\n",
    "\n",
    "run_batch.add_test(test_common_dense)\n",
    "\n",
    "# run all models against the same batch dataset\n",
    "run_batch.run_all()\n",
    "\n",
    "print('\\nTest accuracy:', run_batch.results[0].eval_results)"
   ],
   "id": "2e98b868ec73286d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A simple pipeline with the Keras _functional_ API",
   "id": "422842e3e21bc460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Keep the input tensor\n",
    "inputs_fn = keras.Input(shape=(1,))\n",
    "\n",
    "print(f\"inputs shape: {inputs_fn.shape}\")\n",
    "\n",
    "print(f\"inputs dtype: {inputs_fn.dtype}\")\n",
    "\n",
    "# pipe input\n",
    "d1 = layers.Dense(32, activation=\"relu\")\n",
    "x = d1(inputs_fn)\n",
    "\n",
    "# pipe thru proc layers\n",
    "d2 = layers.Dense(16, activation=\"sigmoid\")\n",
    "x = d2(x)\n",
    "d3 = layers.Dense(8, activation=\"softmax\")\n",
    "x = d3(x)\n",
    "\n",
    "# use final layer to reduce to output\n",
    "final_layer = layers.Dense(1, activation=\"linear\")\n",
    "outputs_fn = final_layer(x)\n",
    "\n",
    "functional_model = keras.Model(inputs=inputs_fn, outputs=outputs_fn, name=\"functional_model_1\")\n",
    "\n",
    "print(f\"functional_model summary: {functional_model.summary()}\")\n",
    "\n",
    "functional_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_absolute_percentage_error\",\n",
    "        \"mean_squared_error\",\n",
    "        \"root_mean_squared_error\",\n",
    "        \"accuracy\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"auc\",\n",
    "        \"binary_accuracy\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "functional_model.fit(run_batch.x_train, run_batch.y_train, epochs=3, verbose=1)\n",
    "\n",
    "loss_and_metrics = functional_model.evaluate(run_batch.x_test, run_batch.y_test, verbose=2)\n",
    "\n",
    "print(f\"Test eval results: {loss_and_metrics}\")"
   ],
   "id": "e7019ccccaa94659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A more readable functional pipeline declaration",
   "id": "e478301b84a30d91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from jkcsoft.ml import keras_utils\n",
    "\n",
    "importlib.reload(keras_utils)\n",
    "\n",
    "proc_layers = [d1, d2, d3, final_layer]\n",
    "\n",
    "composite_model = keras_utils.compose_layers(inputs_fn, proc_layers, verbose=False)\n",
    "\n",
    "print(f\"composite_model summary: {composite_model.summary()}\")\n",
    "\n",
    "composite_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "#        \"mean_absolute_error\",\n",
    "        \"mean_absolute_percentage_error\",\n",
    "#        \"mean_squared_error\",\n",
    "#        \"root_mean_squared_error\",\n",
    "#        \"accuracy\",\n",
    "#        \"precision\",\n",
    "#        \"recall\",\n",
    "#        \"auc\",\n",
    "#        \"binary_accuracy\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "composite_model.fit(run_batch.x_train, run_batch.y_train, epochs=3, verbose=1)\n",
    "\n",
    "loss_and_metrics = composite_model.evaluate(run_batch.x_test, run_batch.y_test, verbose=2)\n",
    "\n",
    "print(f\"Test eval results: {loss_and_metrics}\")"
   ],
   "id": "afd9f15c2ad0b8b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A _functional_ model loaded into our `RunBatch` apparatus",
   "id": "bbee7ecdf45019e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "test_common_dense_fn = ModelTest().set_description(\"Common Dense Sequence\").set_model(functional_model)\n",
    "test_common_dense_fn.set_fit_epochs(10)\n",
    "test_common_dense_fn.compile_model(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "#        \"mean_absolute_error\",\n",
    "        \"mean_absolute_percentage_error\",\n",
    "#        \"mean_squared_error\",\n",
    "#        \"root_mean_squared_error\",\n",
    "#        \"accuracy\",\n",
    "#        \"precision\",\n",
    "#        \"recall\",\n",
    "#        \"auc\",\n",
    "#        \"binary_accuracy\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_common_dense_fn.model.summary()\n",
    "\n",
    "test_common_dense_fn.model.fit(run_batch.x_train, run_batch.y_train, epochs=10, verbose=1)\n",
    "\n",
    "run_batch.add_test(test_common_dense_fn)\n",
    "\n",
    "run_batch.run_all()\n",
    "\n",
    "for i, result in enumerate(run_batch.results):\n",
    "    print(f\"Test {i} eval results: {result.eval_results}\")\n"
   ],
   "id": "448674ee8410b86e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
